import os
import random
import requests
import numpy as np
import sounddevice as sd
import torch
import openai
import webbrowser
import scipy.io.wavfile as wavfile
from datetime import datetime
from vosk import Model, KaldiRecognizer
import json
import dotenv

from dotenv import load_dotenv

load_dotenv()
# ===================== –ù–ê–°–¢–†–û–ô–ö–ò =====================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SAMPLE_RATE = 16000
RECORD_SECONDS = 5
DEVICE = "cpu"
city = "–ò–∂–µ–≤—Å–∫"
DIALOG_HISTORY = []
MAX_HISTORY = 5

# –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ Vosk (–∏–∑–º–µ–Ω–∏, –µ—Å–ª–∏ –ø–∞–ø–∫–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –∏–Ω–∞—á–µ)
VOSK_MODEL_PATH = "vosk-model-small-ru"

openai.api_key = OPENAI_API_KEY

# –°—Å—ã–ª–∫–∏ –Ω–∞ –º—É–∑—ã–∫—É
MUSIC_LINKS = [
    "https://www.youtube.com/watch?v=ZYAPgPH9hsI",
    "https://www.youtube.com/watch?v=BN1WwnEDWAM",
    "https://www.youtube.com/watch?v=dQw4w9WgXcQ",
]

# –ó–∞–º–µ–Ω—ã –¥–ª—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏ —Ü–∏—Ñ—Ä
WEATHER_REPLACE = {
    "10": " –¥–µ—Å—è—Ç—å", "11": " –æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç—å", "12": " –¥–≤–µ–Ω–∞–¥—Ü–∞—Ç—å",
    "13": " —Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å", "14": " —á–µ—Ç—ã—Ä–Ω–∞–¥—Ü–∞—Ç—å", "15": " –ø—è—Ç–Ω–∞–¥—Ü–∞—Ç—å",
    "16": " —à–µ—Å—Ç–Ω–∞–¥—Ü–∞—Ç—å", "17": " —Å–µ–º–Ω–∞–¥—Ü–∞—Ç—å", "18": " –≤–æ—Å–µ–º–Ω–∞–¥—Ü–∞—Ç—å",
    "19": " –¥–µ–≤—è—Ç–Ω–∞–¥—Ü–∞—Ç—å", "20": " –¥–≤–∞–¥—Ü–∞—Ç—å", "21": " –¥–≤–∞–¥—Ü–∞—Ç—å –æ–¥–∏–Ω",
    "22": " –¥–≤–∞–¥—Ü–∞—Ç—å –¥–≤–∞", "23": " –¥–≤–∞–¥—Ü–∞—Ç—å —Ç—Ä–∏", "24": " –¥–≤–∞–¥—Ü–∞—Ç—å —á–µ—Ç—ã—Ä–µ",
    "25": " –¥–≤–∞–¥—Ü–∞—Ç—å –ø—è—Ç—å", "30": " —Ç—Ä–∏–¥—Ü–∞—Ç—å", "35": " —Ç—Ä–∏–¥—Ü–∞—Ç—å –ø—è—Ç—å", "40": " —Å–æ—Ä–æ–∫",
    "-": "–º–∏–Ω—É—Å ", "C": " –≥—Ä–∞–¥—É—Å–æ–≤", "¬∞C": " –≥—Ä–∞–¥—É—Å–æ–≤",
    "0": " –Ω–æ–ª—å", "1": " –æ–¥–∏–Ω", "2": " –¥–≤–∞", "3": " —Ç—Ä–∏", "4": " —á–µ—Ç—ã—Ä–µ",
    "5": " –ø—è—Ç—å", "6": " —à–µ—Å—Ç—å", "7": " —Å–µ–º—å", "8": " –≤–æ—Å–µ–º—å", "9": " –¥–µ–≤—è—Ç—å"
}

HOURS = {
    0: "–ø–æ–ª–Ω–æ—á—å", 1: "—á–∞—Å", 2: "–¥–≤–∞", 3: "—Ç—Ä–∏", 4: "—á–µ—Ç—ã—Ä–µ", 5: "–ø—è—Ç—å",
    6: "—à–µ—Å—Ç—å", 7: "—Å–µ–º—å", 8: "–≤–æ—Å–µ–º—å", 9: "–¥–µ–≤—è—Ç—å", 10: "–¥–µ—Å—è—Ç—å",
    11: "–æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç—å", 12: "–¥–≤–µ–Ω–∞–¥—Ü–∞—Ç—å", 13: "—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å", 14: "—á–µ—Ç—ã—Ä–Ω–∞–¥—Ü–∞—Ç—å",
    15: "–ø—è—Ç–Ω–∞–¥—Ü–∞—Ç—å", 16: "—à–µ—Å—Ç–Ω–∞–¥—Ü–∞—Ç—å", 17: "—Å–µ–º–Ω–∞–¥—Ü–∞—Ç—å", 18: "–≤–æ—Å–µ–º–Ω–∞–¥—Ü–∞—Ç—å",
    19: "–¥–µ–≤—è—Ç–Ω–∞–¥—Ü–∞—Ç—å", 20: "–¥–≤–∞–¥—Ü–∞—Ç—å", 21: "–¥–≤–∞–¥—Ü–∞—Ç—å –æ–¥–∏–Ω", 22: "–¥–≤–∞–¥—Ü–∞—Ç—å –¥–≤–∞", 23: "–¥–≤–∞–¥—Ü–∞—Ç—å —Ç—Ä–∏"
}

# ===================== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====================
print("–ó–∞–≥—Ä—É–∂–∞—é Vosk –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...")
if not os.path.exists(VOSK_MODEL_PATH):
    print(f"–û–®–ò–ë–ö–ê: –ü–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—å—é –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {VOSK_MODEL_PATH}")
    print("–°–∫–∞—á–∞–π –º–æ–¥–µ–ª—å —Å https://alphacephei.com/vosk/models –∏ –ø–æ–ª–æ–∂–∏ —Ä—è–¥–æ–º")
    exit(1)

vosk_model = Model(VOSK_MODEL_PATH)

print("–ó–∞–≥—Ä—É–∂–∞—é Silero TTS...")
tts_model, _ = torch.hub.load('snakers4/silero-models', 'silero_tts', language='ru', speaker='v4_ru')
tts_model.to(DEVICE)


# ===================== –£–¢–ò–õ–ò–¢–´ =====================
def play_wav(filepath: str, fallback: str = None):
    if os.path.exists(filepath):
        try:
            rate, data = wavfile.read(filepath)
            data = data.astype(np.float32) / (32768 if data.dtype == np.int16 else 2147483648)
            sd.play(data, samplerate=rate)
            sd.wait()
            return
        except Exception as e:
            print(f"[–û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è]: {e}")
    if fallback:
        speak(fallback)


def speak(text: str):
    if not text.strip():
        return
    text = text.replace("–î–∂–∞—Ä–≤–∏—Å", "–î–∂+–∞—Ä–≤–∏—Å") \
        .replace("—Å—ç—Ä", "—Å+—ç—Ä") \
        .replace("–°—ç—Ä", "–°+—ç—Ä")

    for k, v in WEATHER_REPLACE.items():
        text = text.replace(k, v)

    text = " ".join(text.split())

    audio = tts_model.apply_tts(text=text, speaker='eugene', sample_rate=48000, put_accent=True, put_yo=True)
    sd.play(audio, samplerate=48000)
    sd.wait()


def record() -> bytes:
    print("üé§ –ì–æ–≤–æ—Ä–∏—Ç–µ...")
    rec = sd.rec(int(RECORD_SECONDS * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='int16')
    sd.wait()
    return rec.tobytes()


def stt(audio_bytes: bytes) -> str:
    rec = KaldiRecognizer(vosk_model, SAMPLE_RATE)
    rec.AcceptWaveform(audio_bytes)
    result = json.loads(rec.Result())
    return result.get("text", "").strip()


def get_weather(city: str = "–ú–æ—Å–∫–≤–∞") -> str:
    try:
        r = requests.get(f"https://wttr.in/{city}?format=%C+%t+%w&lang=ru&T", timeout=8)
        if r.status_code != 200:
            return "–ü–æ–≥–æ–¥–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —Å—ç—Ä."
        raw = r.text.strip()
        raw = raw.replace("‚òÅÔ∏è", "–æ–±–ª–∞—á–Ω–æ").replace("‚òÄÔ∏è", "—è—Å–Ω–æ") \
            .replace("üåßÔ∏è", "–¥–æ–∂–¥—å").replace("‚ùÑÔ∏è", "—Å–Ω–µ–≥").replace("üå´", "—Ç—É–º–∞–Ω")
        raw = raw.replace("–º/—Å", "–º–µ—Ç—Ä–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É")
        return f"–ü–æ–≥–æ–¥–∞ –≤ –≥–æ—Ä–æ–¥–µ {city}: {raw}, —Å—ç—Ä."
    except:
        return "–ù–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞, —Å—ç—Ä."


def get_time() -> str:
    h, m = datetime.now().hour, datetime.now().minute
    hour_str = HOURS.get(h, str(h))
    if m == 0:
        return f"–°–µ–π—á–∞—Å {hour_str} —á–∞—Å–æ–≤ —Ä–æ–≤–Ω–æ, —Å—ç—Ä."
    if m == 30:
        return f"–°–µ–π—á–∞—Å {hour_str} –ø–æ–ª–æ–≤–∏–Ω–∞, —Å—ç—Ä."
    if m == 1:
        return f"–°–µ–π—á–∞—Å {hour_str} —á–∞—Å –∏ –æ–¥–Ω–∞ –º–∏–Ω—É—Ç–∞, —Å—ç—Ä."
    suffix = "–º–∏–Ω—É—Ç" if m % 10 in (0, 5, 6, 7, 8, 9) or 11 <= m <= 19 else \
        "–º–∏–Ω—É—Ç–∞" if m % 10 == 1 else "–º–∏–Ω—É—Ç—ã"
    return f"–°–µ–π—á–∞—Å {hour_str} —á–∞—Å–æ–≤ –∏ {m} {suffix}, —Å—ç—Ä."


def gpt_query(text: str) -> str:
    global DIALOG_HISTORY
    try:
        # –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        DIALOG_HISTORY.append({"role": "user", "content": text})

        # –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
        messages = [
            {"role": "system",
             "content": "–¢—ã –î–∂–∞—Ä–≤–∏—Å ‚Äî –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π –ò–ò –¢–æ–Ω–∏ –°—Ç–∞—Ä–∫–∞ –∏–∑ —Ñ–∏–ª—å–º–∞ –∂–µ–ª–µ–∑–Ω—ã–π —á–µ–ª–æ–≤–µ–∫. –¢—ã - —Å–∞–º—ã–π —É–º–Ω—ã–π –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ –º–∏—Ä–µ. –í—Å–µ–≥–¥–∞ –æ–±—Ä–∞—â–∞–π—Å—è ¬´—Å—ç—Ä¬ª. –°—Ç–∏–ª—å: —É–≤–µ—Ä–µ–Ω–Ω—ã–π, —Å –∏—Ä–æ–Ω–∏–µ–π, –∫—Ä–∞—Ç–∫–æ. –Ø - —Ç–≤–æ–π —Ö–æ–∑—è–∏–Ω. "},
            *DIALOG_HISTORY[-MAX_HISTORY * 2:]  # user + assistant
        ]

        resp = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            timeout=15
        )

        answer = resp.choices[0].message.content

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        DIALOG_HISTORY.append({"role": "assistant", "content": answer})

        return answer

    except Exception as e:
        return "–°–≤—è–∑—å —Å —Å–µ—Ä–≤–µ—Ä–æ–º –ø–æ—Ç–µ—Ä—è–Ω–∞, —Å—ç—Ä."

# ===================== MAIN =====================
if __name__ == "__main__":
    play_wav('jarvis_sounds/greet2.wav', "–î–∂+–∞—Ä–≤–∏—Å –æ–Ω–ª+–∞–π–Ω. –ì–æ—Ç+–æ–≤ –∫ –≤+–∞—à–∏–º —Ä–∞—Å–ø–æ—Ä—è–∂+–µ–Ω–∏—è–º, —Å+—ç—Ä.")
    print("–î–∂–∞—Ä–≤–∏—Å –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω \n")

    exit_cmds = ["–≤—ã—Ö–æ–¥", "—Å—Ç–æ–ø", "–ø–æ–∫–∞", "–æ—Ç–∫–ª—é—á–∞–π—Å—è", "–≤—ã–∫–ª—é—á–∏—Å—å", "–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è"]
    pause_cmds = ["–¥–∂–∞—Ä–≤–∏—Å", "–ø—Ä–æ–¥–æ–ª–∂–∞–µ–º", "–≤–æ–∑–æ–±–Ω–æ–≤–∏", "–≤–µ—Ä–Ω–∏—Å—å"]

    STOP = False

    while True:
        audio_bytes = record()
        text = stt(audio_bytes)

        if not text:
            continue

        print("–í—ã —Å–∫–∞–∑–∞–ª–∏:", text)
        lower = text.lower()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –ø–∞—É–∑—ã
        if STOP:
            if any(cmd in lower for cmd in pause_cmds):
                STOP = False
                play_wav('jarvis_sounds/restart.wav', "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º, —Å—ç—Ä.")
            continue

        # –ö–æ–º–∞–Ω–¥—ã –≤—ã—Ö–æ–¥–∞
        if any(cmd in lower for cmd in exit_cmds):
            play_wav('jarvis_sounds/off.wav', "–û—Ç–∫–ª—é—á+–∞—é—Å—å. –í—Å–µ–≥+–æ —Ö–æ—Ä+–æ—à–µ–≥–æ, —Å+—ç—Ä.")
            break

        # –ú—É–∑—ã–∫–∞ ‚Äî —Å –ø–∞—É–∑–æ–π
        if any(w in lower for w in ["–≤–∫–ª—é—á–∏ –º—É–∑—ã–∫—É", "–º—É–∑—ã–∫—É", "–≤–∫–ª—é—á–∏—Ç—å –º—É–∑—ã–∫—É", "–∏–≥—Ä–∞–π –º—É–∑—ã–∫—É", "–º—É–∑—ã–∫–∞"]):
            link = random.choice(MUSIC_LINKS)
            webbrowser.open(link)
            speak("–ú—É–∑—ã–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞, —Å—ç—Ä. –ü—Ä–∏—è—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è.")
            STOP = True
            continue
        if "–ø–∞—É–∑–∞" in lower:
            play_wav('jarvis_sounds/–ö–∞–∫ –ø–æ–∂–µ–ª–∞–µ—Ç–µ .wav', "–û—Ç–∫–ª—é—á+–∞—é—Å—å. –í—Å–µ–≥+–æ —Ö–æ—Ä+–æ—à–µ–≥–æ, —Å+—ç—Ä.")
            STOP = True
            continue

        # –ü–æ–≥–æ–¥–∞
        if any(w in lower for w in ["–ø–æ–≥–æ–¥–∞", "–ø–æ–≥–æ–¥—É"]):
            weather = get_weather(city)
            print("–î–∂–∞—Ä–≤–∏—Å:", weather)
            speak(weather)
            continue

        # –í—Ä–µ–º—è
        if any(w in lower for w in ["–≤—Ä–µ–º—è", "–∫–æ—Ç–æ—Ä—ã–π —á–∞—Å", "—Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏"]):
            time_str = get_time()
            print("–î–∂–∞—Ä–≤–∏—Å:", time_str)
            speak(time_str)
            continue

        # –í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî —á–µ—Ä–µ–∑ GPT
        answer = gpt_query(text)
        print("–î–∂–∞—Ä–≤–∏—Å:", answer)
        speak(answer)
